{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI - Neural Networks\n",
    "## Project 6 - Traffic\n",
    "\n",
    "[Course Link](https://cs50.harvard.edu/ai/)\n",
    "\n",
    "[Project Instructions](https://cs50.harvard.edu/ai/projects/5/traffic/)\n",
    "\n",
    "## Instructions\n",
    "As research continues in the development of self-driving cars, one of the key challenges is computer vision, allowing these cars to develop an understanding of their environment from digital images. In particular, this involves the ability to recognize and distinguish road signs – stop signs, speed limit signs, yield signs, and more.\n",
    "\n",
    "In this project, you’ll use TensorFlow to build a neural network to classify road signs based on an image of those signs. To do so, you’ll need a labeled dataset: a collection of images that have already been categorized by the road sign represented in them.\n",
    "\n",
    "Several such data sets exist, but for this project, we’ll use the German Traffic Sign Recognition Benchmark (GTSRB) dataset, which contains thousands of images of 43 different kinds of road signs.\n",
    "\n",
    "## Important Note:\n",
    "The images used for this project came from a directory called 'gtrsb' that I downloaded directly from the project instructions link provided above. There are over 250mb of image data included, therefore I did not upload them to github. The code below does work however after downloading the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 10\n",
    "IMG_WIDTH = 30\n",
    "IMG_HEIGHT = 30\n",
    "NUM_CATEGORIES = 43\n",
    "TEST_SIZE = 0.4\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Get image arrays and labels for all image files\n",
    "    images, labels = load_data('gtsrb')\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    labels = tf.keras.utils.to_categorical(labels)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
    "    )\n",
    "\n",
    "    # Get a compiled neural network\n",
    "    model = get_model()\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Fit model on training data\n",
    "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
    "\n",
    "    # Evaluate neural network performance\n",
    "    model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "    # Save model to file\n",
    "    filename = 'model.h5'\n",
    "    model.save(filename)\n",
    "    print(f\"Model saved as: {filename}.\")\n",
    "\n",
    "\n",
    "def load_data(d):\n",
    "    \"\"\"\n",
    "    Load image data from directory `data_dir`.\n",
    "\n",
    "    Assume `data_dir` has one directory named after each category, numbered\n",
    "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
    "    number of image files.\n",
    "\n",
    "    Return tuple `(images, labels)`. `images` should be a list of all\n",
    "    of the images in the data directory, where each image is formatted as a\n",
    "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
    "    be a list of integer labels, representing the categories for each of the\n",
    "    corresponding `images`.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for directory in os.listdir(d):\n",
    "        for image in os.listdir(f'{d}/{directory}'):\n",
    "            im = cv2.imread(f'{d}/{directory}/{image}')\n",
    "            res_im = cv2.resize(im, (30, 30))\n",
    "            images.append(res_im)\n",
    "            labels.append(int(directory))\n",
    "          \n",
    "    return images,labels\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"\n",
    "    Returns a compiled convolutional neural network model. Assume that the\n",
    "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
    "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
    "    \"\"\"\n",
    "    # Create a convolutional neural network\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        # Convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "        tf.keras.layers.Conv2D(\n",
    "            32, (3, 3), activation=\"relu\", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "        ),\n",
    "\n",
    "        # Max-pooling layer, using 2x2 pool size\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        # Flatten units\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        # Add a hidden layer with dropout\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        #tf.keras.layers.Dropout(0.1),\n",
    "        \n",
    "\n",
    "        # Add an output layer with output units for all image types (43 in total)\n",
    "        tf.keras.layers.Dense(NUM_CATEGORIES, activation=\"softmax\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15984 samples\n",
      "Epoch 1/10\n",
      "15984/15984 [==============================] - 9s 592us/sample - loss: 4.6532 - accuracy: 0.5719\n",
      "Epoch 2/10\n",
      "15984/15984 [==============================] - 10s 600us/sample - loss: 0.4936 - accuracy: 0.8737\n",
      "Epoch 3/10\n",
      "15984/15984 [==============================] - 9s 579us/sample - loss: 0.3298 - accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "15984/15984 [==============================] - 9s 578us/sample - loss: 0.2340 - accuracy: 0.9403\n",
      "Epoch 5/10\n",
      "15984/15984 [==============================] - 9s 579us/sample - loss: 0.1961 - accuracy: 0.9496\n",
      "Epoch 6/10\n",
      "15984/15984 [==============================] - 9s 576us/sample - loss: 0.2796 - accuracy: 0.9356\n",
      "Epoch 7/10\n",
      "15984/15984 [==============================] - 9s 584us/sample - loss: 0.1734 - accuracy: 0.9572\n",
      "Epoch 8/10\n",
      "15984/15984 [==============================] - 9s 586us/sample - loss: 0.1664 - accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "15984/15984 [==============================] - 9s 591us/sample - loss: 0.2001 - accuracy: 0.9571\n",
      "Epoch 10/10\n",
      "15984/15984 [==============================] - 9s 589us/sample - loss: 0.1930 - accuracy: 0.9561\n",
      "10656/10656 - 3s - loss: 0.4001 - accuracy: 0.9413\n",
      "Model saved as: model.h5.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
